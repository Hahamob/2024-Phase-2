{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSA 2024 Phase 2 - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Find all variables and understand them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = 'D:/Download/store_sales_utf8.csv'\n",
    "data = pd.read_csv(output_file_path, encoding='utf-8')\n",
    "\n",
    "# 1. Find all variables and understand them\n",
    "# Display the first ten instances\n",
    "print(data.head(10))\n",
    "\n",
    "# Display key statistical metrics\n",
    "print(data.describe())\n",
    "\n",
    "# Show data types of each column\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Clean data\n",
    "# Handling missing values\n",
    "data_cleaned = data.dropna()\n",
    "\n",
    "numeric_cols = data_cleaned.select_dtypes(include=['float64', 'int64']).columns\n",
    "data_numeric = data_cleaned[numeric_cols]\n",
    "\n",
    "# Handling outliers\n",
    "Q1 = data_numeric.quantile(0.25)\n",
    "Q3 = data_numeric.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "data_numeric = data_numeric[~((data_numeric < (Q1 - 1.5 * IQR)) | (data_numeric > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "# Normalizing data\n",
    "scaler = StandardScaler()\n",
    "data_numeric[numeric_cols] = scaler.fit_transform(data_numeric[numeric_cols])\n",
    "\n",
    "data_cleaned = pd.concat([data_numeric, data_cleaned.drop(columns=numeric_cols)], axis=1)\n",
    "\n",
    "# Display the cleaned data\n",
    "print(data_cleaned.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Visualise data\n",
    "\n",
    "# Bar chart for categorical variables\n",
    "categorical_columns = data_cleaned.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    data_cleaned[col].value_counts().plot(kind='bar')\n",
    "    plt.title(f'{col} Bar Chart')\n",
    "    plt.show()\n",
    "\n",
    "# Histogram for numerical variables\n",
    "for col in numeric_cols:\n",
    "    data_cleaned[col].hist(bins=30)\n",
    "    plt.title(f'{col} Histogram')\n",
    "    plt.show()\n",
    "\n",
    "# Box plot for numerical variables\n",
    "for col in numeric_cols:\n",
    "    sns.boxplot(x=data_cleaned[col])\n",
    "    plt.title(f'{col} Box Plot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identify correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Identify correlated variables\n",
    "# Compute correlation matrix\n",
    "correlation_matrix = data_numeric.corr()\n",
    "\n",
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Select most relevant features\n",
    "target_column = 'your_target_column'  # Replace with your actual target column\n",
    "threshold = 0.5\n",
    "if target_column in correlation_matrix.columns:\n",
    "    relevant_features = correlation_matrix[abs(correlation_matrix[target_column]) > threshold].index\n",
    "    print(relevant_features)\n",
    "    data_selected = data_numeric[relevant_features]\n",
    "\n",
    "    # Display the selected data\n",
    "    print(data_selected.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we performed the following steps for data analysis and preprocessing:\n",
    "1. Loaded the dataset and displayed the first ten instances.\n",
    "2. Provided key statistical metrics including mean and standard deviation.\n",
    "3. Visualized numerical columns using bar charts, histograms, and box plots.\n",
    "4. Handled missing values by removing instances with missing data.\n",
    "5. Removed outliers using the interquartile range (IQR) method.\n",
    "6. Normalized the numerical columns to standardize the feature values.\n",
    "7. Computed and visualized the correlation matrix to identify relevant features.\n",
    "8. Selected the most relevant features based on a correlation threshold of 0.5.\n",
    "These steps helped us clean the data and prepare it for machine learning model training and evaluation. We found interesting trends and patterns during the analysis, such as the strong correlation between certain numerical columns and the target variable. These insights will guide our feature selection and model development process.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "c1a2242e7081b4f0929018da2a8cc567af1f3cf95e7af08c98cfb4addbb6241a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
