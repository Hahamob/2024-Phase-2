{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3c1cb34",
   "metadata": {},
   "source": [
    "# MSA 2024 Phase 2 - Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aa5f79",
   "metadata": {},
   "source": [
    "summary:\n",
    "In this notebook, we performed the following steps:\n",
    "\n",
    "1. Organized the image data into subfolders based on their class labels using the provided CSV file.\n",
    "2. Loaded the image data from the organized directories and split it into training, validation, and test sets using data generators.\n",
    "3. Built a Convolutional Neural Network (CNN) model to classify the CIFAR-10 images.\n",
    "4. Trained the model on the training set and evaluated it on the validation set.\n",
    "5. Predicted the classes of the test set images using the trained model and saved the predictions.\n",
    "\n",
    "Our CNN model achieved a prediction on the test dataset. The evaluation metrics could not be calculated without the true labels. Future steps could include providing the true labels for the test set to perform a comprehensive evaluation.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Experiment with different CNN architectures, such as deeper networks or architectures like ResNet and VGG.\n",
    "2. Perform hyperparameter tuning using techniques like grid search or random search.\n",
    "3. Apply data augmentation techniques to artificially increase the size of the training set.\n",
    "4. Gather more data to train the model, if possible, to improve its generalization capabilities.\n",
    "5. Continuously validate the model's performance on new data to ensure its robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f1c5d8",
   "metadata": {},
   "source": [
    "**Before start working on the competition, please ensure all required libraries are installed and properly set up on your system**:\n",
    "\n",
    "- `python >= 3.6`,\n",
    "- `tensorFlow >= 2.0`,\n",
    "- `keras >= 2.3`,\n",
    "\n",
    "and any neccassary liburaries for data manipulation and processing, e.g., `numpy`, `pandas`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d550cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc85f3a2",
   "metadata": {},
   "source": [
    "### 1. Data loading & preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49efe468",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset contains 60,000 images(32x32x3) in 10 different classes, with 6,000 images in each class. You can download the dataset directly from the competition webpage.\n",
    "\n",
    "**To train the model, you are expected to use the training label provided in train.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3985907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# set path\n",
    "train_csv_path = 'D:/Download/nzmsa-2024/train.csv'\n",
    "train_dir = 'D:/Download/nzmsa-2024/cifar10_images/train'\n",
    "organized_train_dir = 'D:/Download/nzmsa-2024/cifar10_images/organized_train'\n",
    "test_dir = 'D:/Download/nzmsa-2024/cifar10_images/test'\n",
    "test_organized_dir = 'D:/Download/nzmsa-2024/cifar10_images/test_organized'\n",
    "\n",
    "# load csv file\n",
    "labels_df = pd.read_csv(train_csv_path)\n",
    "\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2)\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Training set and validation set generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    organized_train_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    seed=101\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    organized_train_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    seed=101\n",
    ")\n",
    "\n",
    "# Test set generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_organized_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=64,\n",
    "    class_mode=None,  \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Check if test_generator successfully loaded the image\n",
    "print(f\"Found {test_generator.samples} images belonging to {test_generator.num_classes} classes in test set.\")\n",
    "\n",
    "train_labels = train_generator.classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ae9e8",
   "metadata": {},
   "source": [
    "### 2. Build & train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3f0331",
   "metadata": {},
   "source": [
    "This code demostrates a simple Multi-Layer Perceptron (MLP) model. However, you are encouraged to experiment with more complex deep learning models and techniques to boost your performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d60add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Dense(128, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 50:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.99\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=200, batch_size=32, callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "# Predict on training and testing sets\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Print training and testing accuracy\n",
    "print(\"Train R^2:\", r2_score(y_train, y_train_pred))\n",
    "print(\"Test R^2:\", r2_score(y_test, y_test_pred))\n",
    "\n",
    "# Evaluate the model\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Train MSE:\", mse_train)\n",
    "print(\"Test MSE:\", mse_test)\n",
    "print(\"Train MAE:\", mae_train)\n",
    "print(\"Test MAE:\", mae_test)\n",
    "\n",
    "# Visualize actual vs predicted values\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_train, y_train_pred)\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Train set\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_test_pred)\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Test set\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save test set predictions\n",
    "test_filenames = [f'image_{i}.png' for i in range(len(y_test_pred))]\n",
    "results = pd.DataFrame({\n",
    "    'Filename': test_filenames,\n",
    "    'Prediction': y_test_pred.flatten()\n",
    "})\n",
    "results.to_csv('D:/Download/nzmsa-2024/cifar10_images/test_predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
